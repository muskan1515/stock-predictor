{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stepwise Regression Backward"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# yahoo finance is used to fetch data \n",
        "import yfinance as yf\n",
        "yf.pdr_override()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input\n",
        "symbol = 'AMD'\n",
        "start = '2014-01-01'\n",
        "end = '2018-08-27'\n",
        "\n",
        "# Read data \n",
        "dataset = yf.download(symbol,start,end)\n",
        "\n",
        "# View Columns\n",
        "dataset.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "            Open  High   Low  Close  Adj Close    Volume\nDate                                                    \n2014-01-02  3.85  3.98  3.84   3.95       3.95  20548400\n2014-01-03  3.98  4.00  3.88   4.00       4.00  22887200\n2014-01-06  4.01  4.18  3.99   4.13       4.13  42398300\n2014-01-07  4.19  4.25  4.11   4.18       4.18  42932100\n2014-01-08  4.23  4.26  4.14   4.18       4.18  30678700",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2014-01-02</th>\n      <td>3.85</td>\n      <td>3.98</td>\n      <td>3.84</td>\n      <td>3.95</td>\n      <td>3.95</td>\n      <td>20548400</td>\n    </tr>\n    <tr>\n      <th>2014-01-03</th>\n      <td>3.98</td>\n      <td>4.00</td>\n      <td>3.88</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>22887200</td>\n    </tr>\n    <tr>\n      <th>2014-01-06</th>\n      <td>4.01</td>\n      <td>4.18</td>\n      <td>3.99</td>\n      <td>4.13</td>\n      <td>4.13</td>\n      <td>42398300</td>\n    </tr>\n    <tr>\n      <th>2014-01-07</th>\n      <td>4.19</td>\n      <td>4.25</td>\n      <td>4.11</td>\n      <td>4.18</td>\n      <td>4.18</td>\n      <td>42932100</td>\n    </tr>\n    <tr>\n      <th>2014-01-08</th>\n      <td>4.23</td>\n      <td>4.26</td>\n      <td>4.14</td>\n      <td>4.18</td>\n      <td>4.18</td>\n      <td>30678700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create more data\n",
        "dataset['Increase/Decrease'] = np.where(dataset['Volume'].shift(-1) > dataset['Volume'],1,0)\n",
        "dataset['Buy_Sell_on_Open'] = np.where(dataset['Open'].shift(-1) > dataset['Open'],1,-1)\n",
        "dataset['Buy_Sell'] = np.where(dataset['Adj Close'].shift(-1) > dataset['Adj Close'],1,-1)\n",
        "dataset['Return'] = dataset['Adj Close'].pct_change()\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "            Open  High   Low  Close  Adj Close    Volume  Increase/Decrease  \\\nDate                                                                          \n2014-01-03  3.98  4.00  3.88   4.00       4.00  22887200                  1   \n2014-01-06  4.01  4.18  3.99   4.13       4.13  42398300                  1   \n2014-01-07  4.19  4.25  4.11   4.18       4.18  42932100                  0   \n2014-01-08  4.23  4.26  4.14   4.18       4.18  30678700                  0   \n2014-01-09  4.20  4.23  4.05   4.09       4.09  30667600                  0   \n\n            Buy_Sell_on_Open  Buy_Sell    Return  \nDate                                              \n2014-01-03                 1         1  0.012658  \n2014-01-06                 1         1  0.032500  \n2014-01-07                 1        -1  0.012107  \n2014-01-08                -1        -1  0.000000  \n2014-01-09                -1         1 -0.021531  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>Increase/Decrease</th>\n      <th>Buy_Sell_on_Open</th>\n      <th>Buy_Sell</th>\n      <th>Return</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2014-01-03</th>\n      <td>3.98</td>\n      <td>4.00</td>\n      <td>3.88</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>22887200</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.012658</td>\n    </tr>\n    <tr>\n      <th>2014-01-06</th>\n      <td>4.01</td>\n      <td>4.18</td>\n      <td>3.99</td>\n      <td>4.13</td>\n      <td>4.13</td>\n      <td>42398300</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.032500</td>\n    </tr>\n    <tr>\n      <th>2014-01-07</th>\n      <td>4.19</td>\n      <td>4.25</td>\n      <td>4.11</td>\n      <td>4.18</td>\n      <td>4.18</td>\n      <td>42932100</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0.012107</td>\n    </tr>\n    <tr>\n      <th>2014-01-08</th>\n      <td>4.23</td>\n      <td>4.26</td>\n      <td>4.14</td>\n      <td>4.18</td>\n      <td>4.18</td>\n      <td>30678700</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2014-01-09</th>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>4.05</td>\n      <td>4.09</td>\n      <td>4.09</td>\n      <td>30667600</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-0.021531</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "(1171, 10)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1171, 646)\n",
            "(1171,)\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "X[:, 0] = labelencoder.fit_transform(X[:, 0])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        " \n",
        "# Avoiding the Dummy Variable Trap\n",
        "X = X[:, 1:]\n",
        " \n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
        " \n",
        "# Fitting Multiple Linear Regression to the Training set\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as sm\n",
        "X = np.append ( arr = np.ones([1171,1]).astype(int), values = X, axis = 1)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt = X[:,[0,1,2,3,4,5]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                       nan\nDate:                Sun, 14 Oct 2018   Prob (F-statistic):                nan\nTime:                        20:36:48   Log-Likelihood:                -3519.4\nNo. Observations:                1171   AIC:                             7041.\nDf Residuals:                    1170   BIC:                             7046.\nDf Model:                           0                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.1697      0.024     49.127      0.000       1.123       1.216\nx1             1.1697      0.024     49.127      0.000       1.123       1.216\nx2             1.1697      0.024     49.127      0.000       1.123       1.216\nx3             1.1697      0.024     49.127      0.000       1.123       1.216\nx4             1.1697      0.024     49.127      0.000       1.123       1.216\nx5             1.1697      0.024     49.127      0.000       1.123       1.216\n==============================================================================\nOmnibus:                      137.680   Durbin-Watson:                   0.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              115.619\nSkew:                           0.684   Prob(JB):                     7.83e-26\nKurtosis:                       2.296   Cond. No.                     1.60e+83\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.73e-163. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"",
            "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.000</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 14 Oct 2018</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>20:36:48</td>     <th>  Log-Likelihood:    </th> <td> -3519.4</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1171</td>      <th>  AIC:               </th> <td>   7041.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1170</td>      <th>  BIC:               </th> <td>   7046.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n<tr>\n  <th>x5</th>    <td>    1.1697</td> <td>    0.024</td> <td>   49.127</td> <td> 0.000</td> <td>    1.123</td> <td>    1.216</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>137.680</td> <th>  Durbin-Watson:     </th> <td>   0.004</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 115.619</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.684</td>  <th>  Prob(JB):          </th> <td>7.83e-26</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.296</td>  <th>  Cond. No.          </th> <td>1.60e+83</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.73e-163. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Opt = X[:,[0,1,3,4,5]]"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_opt_train, X_opt_test, y_opt_train, y_opt_test = train_test_split(X_Opt, y, test_size = 1/3, random_state = 0)\n",
        "regressor_opt = LinearRegression()\n",
        "regressor_opt.fit(X_opt_train, y_opt_train)\n",
        " \n",
        "y_opt_pred = regressor_opt.predict(X_opt_test)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_opt_pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "array([6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718, 6.9558718,\n       6.9558718])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "version": "3.5.5",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}